{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "# python imports\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "      adjust_learning_rate, save_checkpoint, clip_gradient\n",
    "\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with arguments:\n",
      "<__main__.Arguments object at 0x7fa0a6c62128>\n"
     ]
    }
   ],
   "source": [
    "class Arguments(object):\n",
    "    def __init__(self, *argdata, **kwargs):\n",
    "        for dictionary in argdata:\n",
    "            for key in dictionary:\n",
    "                setattr(self, key, dictionary[key])\n",
    "        for key in kwargs:\n",
    "            setattr(self, key, kwargs[key])\n",
    "#2_5_8274\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse input arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Train a Fast R-CNN network')\n",
    "    args = Arguments({\n",
    "        'dataset': 'pascal_voc_0712',\n",
    "        'net': 'res50',\n",
    "        'start_epoch': 1,\n",
    "        'max_epochs': 50,\n",
    "        'disp_interval': 100,\n",
    "        'checkpoint_interval': 10000,\n",
    "        'save_dir': 'models',\n",
    "        'num_workers': 0,\n",
    "        'cuda': torch.cuda.is_available(),\n",
    "        'large_scale': False,\n",
    "        'optimizer': 'sgd',\n",
    "        'class_agnostic': False,\n",
    "        'batch_size': 8,\n",
    "        'lr': 0.0006,\n",
    "        'lr_decay_step': 8,\n",
    "        'lr_decay_gamma': 0.1,\n",
    "        'resume': False,\n",
    "        'checksession': 10,\n",
    "        'checkepoch': 9,\n",
    "        'checkpoint': 3723,\n",
    "        'use_tfboard': False,\n",
    "        'session': 12,\n",
    "        'mGPUs': True\n",
    "    })\n",
    "    \n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "print('Running with arguments:')\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"pascal_voc\":\n",
    "    args.imdb_name = \"voc_2007_trainval\"\n",
    "    args.imdbval_name = \"voc_2007_test\"\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20']\n",
    "elif args.dataset == \"pascal_voc_0712\":\n",
    "    args.imdb_name = \"voc_2007_train+voc_2012_train\"\n",
    "    args.imdbval_name = \"voc_2007_test\"\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc_2007_train+voc_2012_train\n"
     ]
    }
   ],
   "source": [
    "print(args.imdb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading cfg file cfgs/res50.yml\n"
     ]
    }
   ],
   "source": [
    "args.cfg_file = \"cfgs/{}_ls.yml\".format(args.net) if args.large_scale else \"cfgs/{}.yml\".format(args.net)\n",
    "print('reading cfg file {}'.format(args.cfg_file))\n",
    "if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "if args.set_cfgs is not None:\n",
    "    cfg_from_list(args.set_cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'ANCHOR_RATIOS': [0.5, 1, 2],\n",
      " 'ANCHOR_SCALES': [8, 16, 32],\n",
      " 'CROP_RESIZE_WITH_MAX_POOL': True,\n",
      " 'CUDA': True,\n",
      " 'DATA_DIR': '/datasets/home/home-01/44/344/abkandoi/faster-rcnn.pytorch/data',\n",
      " 'DEDUP_BOXES': 0.0625,\n",
      " 'EPS': 1e-14,\n",
      " 'EXP_DIR': 'res50',\n",
      " 'FEAT_STRIDE': [16],\n",
      " 'GPU_ID': 0,\n",
      " 'MATLAB': 'matlab',\n",
      " 'MAX_NUM_GT_BOXES': 20,\n",
      " 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,\n",
      "               'FIXED_LAYERS': 5,\n",
      "               'REGU_DEPTH': False,\n",
      "               'WEIGHT_DECAY': 4e-05},\n",
      " 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),\n",
      " 'POOLING_MODE': 'align',\n",
      " 'POOLING_SIZE': 7,\n",
      " 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},\n",
      " 'RNG_SEED': 3,\n",
      " 'ROOT_DIR': '/datasets/home/home-01/44/344/abkandoi/faster-rcnn.pytorch',\n",
      " 'TEST': {'BBOX_REG': True,\n",
      "          'HAS_RPN': True,\n",
      "          'MAX_SIZE': 1000,\n",
      "          'MODE': 'nms',\n",
      "          'NMS': 0.3,\n",
      "          'PROPOSAL_METHOD': 'gt',\n",
      "          'RPN_MIN_SIZE': 16,\n",
      "          'RPN_NMS_THRESH': 0.7,\n",
      "          'RPN_POST_NMS_TOP_N': 300,\n",
      "          'RPN_PRE_NMS_TOP_N': 6000,\n",
      "          'RPN_TOP_N': 5000,\n",
      "          'SCALES': [600],\n",
      "          'SVM': False},\n",
      " 'TRAIN': {'ASPECT_GROUPING': False,\n",
      "           'BATCH_SIZE': 256,\n",
      "           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],\n",
      "           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],\n",
      "           'BBOX_NORMALIZE_TARGETS': True,\n",
      "           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,\n",
      "           'BBOX_REG': True,\n",
      "           'BBOX_THRESH': 0.5,\n",
      "           'BG_THRESH_HI': 0.5,\n",
      "           'BG_THRESH_LO': 0.0,\n",
      "           'BIAS_DECAY': False,\n",
      "           'BN_TRAIN': False,\n",
      "           'DISPLAY': 20,\n",
      "           'DOUBLE_BIAS': False,\n",
      "           'FG_FRACTION': 0.25,\n",
      "           'FG_THRESH': 0.5,\n",
      "           'GAMMA': 0.1,\n",
      "           'HAS_RPN': True,\n",
      "           'IMS_PER_BATCH': 1,\n",
      "           'LEARNING_RATE': 0.001,\n",
      "           'MAX_SIZE': 1000,\n",
      "           'MOMENTUM': 0.9,\n",
      "           'PROPOSAL_METHOD': 'gt',\n",
      "           'RPN_BATCHSIZE': 256,\n",
      "           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'RPN_CLOBBER_POSITIVES': False,\n",
      "           'RPN_FG_FRACTION': 0.5,\n",
      "           'RPN_MIN_SIZE': 8,\n",
      "           'RPN_NEGATIVE_OVERLAP': 0.3,\n",
      "           'RPN_NMS_THRESH': 0.7,\n",
      "           'RPN_POSITIVE_OVERLAP': 0.7,\n",
      "           'RPN_POSITIVE_WEIGHT': -1.0,\n",
      "           'RPN_POST_NMS_TOP_N': 2000,\n",
      "           'RPN_PRE_NMS_TOP_N': 12000,\n",
      "           'SCALES': [600],\n",
      "           'SNAPSHOT_ITERS': 5000,\n",
      "           'SNAPSHOT_KEPT': 3,\n",
      "           'SNAPSHOT_PREFIX': 'res50_faster_rcnn',\n",
      "           'STEPSIZE': [30000],\n",
      "           'SUMMARY_INTERVAL': 180,\n",
      "           'TRIM_HEIGHT': 600,\n",
      "           'TRIM_WIDTH': 600,\n",
      "           'TRUNCATED': False,\n",
      "           'USE_ALL_GT': True,\n",
      "           'USE_FLIPPED': True,\n",
      "           'USE_GT': False,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'USE_GPU_NMS': True}\n"
     ]
    }
   ],
   "source": [
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "np.random.seed(cfg.RNG_SEED)\n",
    "\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available() and not args.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampler(Sampler):\n",
    "    def __init__(self, train_size, batch_size):\n",
    "        self.num_data = train_size\n",
    "        self.num_per_batch = int(train_size / batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.range = torch.arange(0,batch_size).view(1, batch_size).long()\n",
    "        self.leftover_flag = False\n",
    "        if train_size % batch_size:\n",
    "            self.leftover = torch.arange(self.num_per_batch*batch_size, train_size).long()\n",
    "            self.leftover_flag = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_num = torch.randperm(self.num_per_batch).view(-1,1) * self.batch_size\n",
    "        self.rand_num = rand_num.expand(self.num_per_batch, self.batch_size) + self.range\n",
    "\n",
    "        self.rand_num_view = self.rand_num.view(-1)\n",
    "\n",
    "        if self.leftover_flag:\n",
    "            self.rand_num_view = torch.cat((self.rand_num_view, self.leftover),0)\n",
    "\n",
    "        return iter(self.rand_num_view)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset `voc_2007_train` for training\n",
      "Set proposal method: gt\n",
      "Appending horizontally-flipped training examples...\n",
      "voc_2007_train gt roidb loaded from /datasets/home/home-01/44/344/abkandoi/faster-rcnn.pytorch/data/cache/voc_2007_train_gt_roidb.pkl\n",
      "done\n",
      "Preparing training data...\n",
      "done\n",
      "Loaded dataset `voc_2012_train` for training\n",
      "Set proposal method: gt\n",
      "Appending horizontally-flipped training examples...\n",
      "voc_2012_train gt roidb loaded from /datasets/home/home-01/44/344/abkandoi/faster-rcnn.pytorch/data/cache/voc_2012_train_gt_roidb.pkl\n",
      "done\n",
      "Preparing training data...\n",
      "done\n",
      "before filtering, there are 29792 images...\n",
      "after filtering, there are 29792 images...\n",
      "29792 roidb entries\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "# -- Note: Use validation set and disable the flipped to enable faster loading.\n",
    "cfg.TRAIN.USE_FLIPPED = True\n",
    "cfg.USE_GPU_NMS = args.cuda\n",
    "imdb, roidb, ratio_list, ratio_index = combined_roidb(args.imdb_name)\n",
    "train_size = len(roidb)\n",
    "\n",
    "print('{:d} roidb entries'.format(len(roidb)))\n",
    "\n",
    "# create path for model's output directory if its doesn't already exist\n",
    "output_dir = '{}/{}/{}'.format(args.save_dir, args.net, args.dataset)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "sampler_batch = sampler(train_size, args.batch_size)\n",
    "\n",
    "dataset = roibatchLoader(roidb, ratio_list, ratio_index, args.batch_size, \\\n",
    "                           imdb.num_classes, training=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,\n",
    "                            sampler=sampler_batch, num_workers=args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(imdb.image_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize the tensor holder here.\n",
    "im_data = torch.FloatTensor(1)\n",
    "im_info = torch.FloatTensor(1)\n",
    "num_boxes = torch.LongTensor(1)\n",
    "gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "# ship to cuda\n",
    "if args.cuda:\n",
    "    im_data = im_data.cuda()\n",
    "    im_info = im_info.cuda()\n",
    "    num_boxes = num_boxes.cuda()\n",
    "    gt_boxes = gt_boxes.cuda()\n",
    "\n",
    "# make variable\n",
    "im_data = Variable(im_data)\n",
    "im_info = Variable(im_info)\n",
    "num_boxes = Variable(num_boxes)\n",
    "gt_boxes = Variable(gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using network res50\n"
     ]
    }
   ],
   "source": [
    "if args.cuda:\n",
    "    cfg.CUDA = True\n",
    "\n",
    "print('Using network {}'.format(args.net))\n",
    "# initilize the network here.\n",
    "if args.net == 'vgg16':\n",
    "    fasterRCNN = vgg16(imdb.classes, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "elif args.net == 'res101':\n",
    "    fasterRCNN = resnet(imdb.classes, 101, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "elif args.net == 'res50':\n",
    "    fasterRCNN = resnet(imdb.classes, 50, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "else:\n",
    "    raise Exception(\"Network {} is not defined\".format(args.net))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from data/pretrained_model/resnet50_caffe.pth\n"
     ]
    }
   ],
   "source": [
    "fasterRCNN.create_architecture()\n",
    "\n",
    "lr = cfg.TRAIN.LEARNING_RATE\n",
    "lr = args.lr  # overwrite if changed in args\n",
    "\n",
    "params = []\n",
    "for key, value in dict(fasterRCNN.named_parameters()).items():\n",
    "    if value.requires_grad:\n",
    "        if 'bias' in key:\n",
    "            params += [{'params':[value],'lr':lr*(cfg.TRAIN.DOUBLE_BIAS + 1), \\\n",
    "                    'weight_decay': cfg.TRAIN.BIAS_DECAY and cfg.TRAIN.WEIGHT_DECAY or 0}]\n",
    "        else:\n",
    "            params += [{'params':[value],'lr':lr, 'weight_decay': cfg.TRAIN.WEIGHT_DECAY}]\n",
    "\n",
    "if args.cuda:\n",
    "    fasterRCNN.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.optimizer == \"adam\":\n",
    "    lr = lr * 0.1\n",
    "    optimizer = torch.optim.Adam(params)\n",
    "elif args.optimizer == \"sgd\":\n",
    "    optimizer = torch.optim.SGD(params, momentum=cfg.TRAIN.MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    load_name = os.path.join(output_dir,\n",
    "      'faster_rcnn_{}_{}_{}.pth'.format(args.checksession, args.checkepoch, args.checkpoint))\n",
    "    print(\"loading checkpoint %s\" % (load_name))\n",
    "    checkpoint = torch.load(load_name)\n",
    "    args.session = checkpoint['session']\n",
    "    args.start_epoch = checkpoint['epoch']\n",
    "    fasterRCNN.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    if 'pooling_mode' in checkpoint.keys():\n",
    "        cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "    print(\"loaded checkpoint %s\" % (load_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mGPUs:\n",
    "    fasterRCNN = nn.DataParallel(fasterRCNN)\n",
    "\n",
    "iters_per_epoch = int(train_size / args.batch_size)\n",
    "\n",
    "# won't be using this probably\n",
    "if args.use_tfboard:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    logger = SummaryWriter(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[session 12][epoch  1][iter    0/3724] loss: 40.0622, lr: 6.00e-04\n",
      "\t\t\tfg/bg=(47/2001), time cost: 5.114526\n",
      "\t\t\trpn_cls: 0.5423, rpn_box: 0.3206, rcnn_cls: 39.1328, rcnn_box 0.0665\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-0fa4151952e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpn_loss_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrpn_loss_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                \u001b[0;34m+\u001b[0m \u001b[0mRCNN_loss_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mRCNN_loss_bbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss_temp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.start_epoch, args.max_epochs + 1):\n",
    "    # setting to train mode\n",
    "    fasterRCNN.train()\n",
    "    loss_temp = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    if epoch % (args.lr_decay_step + 1) == 0:\n",
    "        adjust_learning_rate(optimizer, args.lr_decay_gamma)\n",
    "        lr *= args.lr_decay_gamma\n",
    "    \n",
    "    data_iter = iter(dataloader)\n",
    "    for step in range(iters_per_epoch):\n",
    "        data = next(data_iter)\n",
    "        with torch.no_grad():\n",
    "            im_data.resize_(data[0].size()).copy_(data[0])\n",
    "            im_info.resize_(data[1].size()).copy_(data[1])\n",
    "            gt_boxes.resize_(data[2].size()).copy_(data[2])\n",
    "            num_boxes.resize_(data[3].size()).copy_(data[3])\n",
    "        \n",
    "        fasterRCNN.zero_grad()\n",
    "        rois, cls_prob, bbox_pred, \\\n",
    "        rpn_loss_cls, rpn_loss_box, \\\n",
    "        RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "        rois_label = fasterRCNN(im_data, im_info, gt_boxes, num_boxes)\n",
    "\n",
    "        loss = rpn_loss_cls.mean() + rpn_loss_box.mean() \\\n",
    "               + RCNN_loss_cls.mean() + RCNN_loss_bbox.mean()\n",
    "        loss_temp += loss.item()\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if args.net == \"vgg16\":\n",
    "            clip_gradient(fasterRCNN, 10.)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % args.disp_interval == 0:\n",
    "            end = time.time()\n",
    "            if step > 0:\n",
    "                loss_temp /= (args.disp_interval + 1)\n",
    "            \n",
    "            if args.mGPUs:\n",
    "                loss_rpn_cls = rpn_loss_cls.mean().item()\n",
    "                loss_rpn_box = rpn_loss_box.mean().item()\n",
    "                loss_rcnn_cls = RCNN_loss_cls.mean().item()\n",
    "                loss_rcnn_box = RCNN_loss_bbox.mean().item()\n",
    "                fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "                bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "            else:\n",
    "                loss_rpn_cls = rpn_loss_cls.item()\n",
    "                loss_rpn_box = rpn_loss_box.item()\n",
    "                loss_rcnn_cls = RCNN_loss_cls.item()\n",
    "                loss_rcnn_box = RCNN_loss_bbox.item()\n",
    "                fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "                bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "            print(\"[session %d][epoch %2d][iter %4d/%4d] loss: %.4f, lr: %.2e\" \\\n",
    "                                % (args.session, epoch, step, iters_per_epoch, loss_temp, lr))\n",
    "            print(\"\\t\\t\\tfg/bg=(%d/%d), time cost: %f\" % (fg_cnt, bg_cnt, end-start))\n",
    "            print(\"\\t\\t\\trpn_cls: %.4f, rpn_box: %.4f, rcnn_cls: %.4f, rcnn_box %.4f\" \\\n",
    "                      % (loss_rpn_cls, loss_rpn_box, loss_rcnn_cls, loss_rcnn_box))\n",
    "            \n",
    "            loss_temp = 0\n",
    "            start = time.time()\n",
    "            \n",
    "    save_name = os.path.join(output_dir, 'faster_rcnn_{}_{}_{}.pth'.format(args.session, epoch, step))\n",
    "    save_checkpoint({\n",
    "      'session': args.session,\n",
    "      'epoch': epoch + 1,\n",
    "      'model': fasterRCNN.module.state_dict() if args.mGPUs else fasterRCNN.state_dict(),\n",
    "      'optimizer': optimizer.state_dict(),\n",
    "      'pooling_mode': cfg.POOLING_MODE,\n",
    "      'class_agnostic': args.class_agnostic,\n",
    "    }, save_name)\n",
    "    \n",
    "    print('saved model to: {}'.format(save_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
