{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.rpn.bbox_transform import clip_boxes\n",
    "# from model.nms.nms_wrapper import nms\n",
    "from model.roi_layers import nms\n",
    "from model.rpn.bbox_transform import bbox_transform_inv\n",
    "from model.utils.net_utils import save_net, load_net, vis_detections\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='models'\n",
    "net='vgg16'\n",
    "dataset='pascal_voc_0712'\n",
    "load_dir='models'\n",
    "\n",
    "lr=0.004\n",
    "optimizer='sgd'\n",
    "\n",
    "large_scale=False\n",
    "class_agnostic=False\n",
    "cuda=torch.cuda.is_available()\n",
    "mGPUs=False\n",
    "\n",
    "session=11\n",
    "epoch=7\n",
    "checkpoint=3723"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset to use for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(cfg.RNG_SEED)\n",
    "\n",
    "if dataset == \"pascal_voc\":\n",
    "    imdb_name = \"voc_2007_trainval\"\n",
    "    imdbval_name = \"voc_2007_test\"\n",
    "    set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20']\n",
    "elif dataset == \"pascal_voc_0712\":\n",
    "    imdb_name = \"voc_2007_train+voc_2012_train\"\n",
    "    imdbval_name = \"voc_2007_test\"\n",
    "    set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = \"cfgs/{}_ls.yml\".format(net) if large_scale else \"cfgs/{}.yml\".format(net)\n",
    "print('reading cfg file {}'.format(cfg_file))\n",
    "if cfg_file is not None:\n",
    "    cfg_from_file(cfg_file)\n",
    "if set_cfgs is not None:\n",
    "    cfg_from_list(set_cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.TRAIN.USE_FLIPPED = False\n",
    "imdb, roidb, ratio_list, ratio_index = combined_roidb(imdbval_name, False)\n",
    "imdb.competition_mode(on=True)\n",
    "\n",
    "print('{:d} roidb entries'.format(len(roidb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Faster R-CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = load_dir + \"/\" + net + \"/\" + dataset\n",
    "if not os.path.exists(input_dir):\n",
    "    raise Exception('There is no input directory for loading network from ' + input_dir)\n",
    "load_name = os.path.join(input_dir,\n",
    "    'faster_rcnn_{}_{}_{}.pth'.format(session, epoch, checkpoint))\n",
    "\n",
    "# initilize the network here.\n",
    "if net == 'vgg16':\n",
    "    fasterRCNN = vgg16(imdb.classes, pretrained=False, class_agnostic=class_agnostic)\n",
    "elif net == 'res101':\n",
    "    fasterRCNN = resnet(imdb.classes, 101, pretrained=False, class_agnostic=class_agnostic)\n",
    "elif net == 'res50':\n",
    "    fasterRCNN = resnet(imdb.classes, 50, pretrained=False, class_agnostic=class_agnostic)\n",
    "else:\n",
    "    print(\"network is not defined\")\n",
    "    pdb.set_trace()\n",
    "\n",
    "fasterRCNN.create_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the checkpoint's state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"load checkpoint %s\" % (load_name))\n",
    "checkpoint = torch.load(load_name)\n",
    "fasterRCNN.load_state_dict(checkpoint['model'])\n",
    "if 'pooling_mode' in checkpoint.keys():\n",
    "    cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "\n",
    "print('load model successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize the tensor holder here.\n",
    "im_data = torch.FloatTensor(1)\n",
    "im_info = torch.FloatTensor(1)\n",
    "num_boxes = torch.LongTensor(1)\n",
    "gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "# ship to cuda\n",
    "if cuda:\n",
    "    im_data = im_data.cuda()\n",
    "    im_info = im_info.cuda()\n",
    "    num_boxes = num_boxes.cuda()\n",
    "    gt_boxes = gt_boxes.cuda()\n",
    "\n",
    "# make variable\n",
    "im_data = Variable(im_data)\n",
    "im_info = Variable(im_info)\n",
    "num_boxes = Variable(num_boxes)\n",
    "gt_boxes = Variable(gt_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move the network to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    cfg.CUDA = True\n",
    "\n",
    "if cuda:\n",
    "    fasterRCNN.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "max_per_image = 100\n",
    "\n",
    "vis=False\n",
    "thresh = 0.0\n",
    "\n",
    "save_name = 'faster_rcnn_10'\n",
    "num_images = len(roidb)\n",
    "print(imdb)\n",
    "all_boxes = [[[] for _ in range(num_images)]\n",
    "           for _ in range(imdb.num_classes)]\n",
    "\n",
    "output_dir = get_output_dir(imdb, save_name)\n",
    "dataset = roibatchLoader(roidb, ratio_list, ratio_index, 1, \\\n",
    "                        imdb.num_classes, training=False, normalize=False)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "                            shuffle=False, num_workers=0,\n",
    "                            pin_memory=True)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "_t = {'im_detect': time.time(), 'misc': time.time()}\n",
    "det_file = os.path.join(output_dir, 'detections.pkl')\n",
    "\n",
    "fasterRCNN.eval()\n",
    "empty_array = np.transpose(np.array([[],[],[],[],[]]), (1,0))\n",
    "for i in range(num_images):\n",
    "    data = next(data_iter)\n",
    "    with torch.no_grad():\n",
    "        im_data.resize_(data[0].size()).copy_(data[0])\n",
    "        im_info.resize_(data[1].size()).copy_(data[1])\n",
    "        gt_boxes.resize_(data[2].size()).copy_(data[2])\n",
    "        num_boxes.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "    det_tic = time.time()\n",
    "    rois, cls_prob, bbox_pred, \\\n",
    "    rpn_loss_cls, rpn_loss_box, \\\n",
    "    RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "    rois_label = fasterRCNN(im_data, im_info, gt_boxes, num_boxes)\n",
    "\n",
    "    scores = cls_prob.data\n",
    "    boxes = rois.data[:, :, 1:5]\n",
    "\n",
    "    if cfg.TEST.BBOX_REG:\n",
    "        # Apply bounding-box regression deltas\n",
    "        box_deltas = bbox_pred.data\n",
    "        if cfg.TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED:\n",
    "        # Optionally normalize targets by a precomputed mean and stdev\n",
    "            if class_agnostic:\n",
    "                box_deltas = box_deltas.view(-1, 4) * torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_STDS).cuda() \\\n",
    "                           + torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_MEANS).cuda()\n",
    "                box_deltas = box_deltas.view(1, -1, 4)\n",
    "            else:\n",
    "                box_deltas = box_deltas.view(-1, 4) * torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_STDS).cuda() \\\n",
    "                           + torch.FloatTensor(cfg.TRAIN.BBOX_NORMALIZE_MEANS).cuda()\n",
    "                box_deltas = box_deltas.view(1, -1, 4 * len(imdb.classes))\n",
    "\n",
    "        pred_boxes = bbox_transform_inv(boxes, box_deltas, 1)\n",
    "        pred_boxes = clip_boxes(pred_boxes, im_info.data, 1)\n",
    "    else:\n",
    "        # Simply repeat the boxes, once for each class\n",
    "        pred_boxes = np.tile(boxes, (1, scores.shape[1]))\n",
    "\n",
    "    pred_boxes /= data[1][0][2].item()\n",
    "\n",
    "    scores = scores.squeeze()\n",
    "    pred_boxes = pred_boxes.squeeze()\n",
    "    det_toc = time.time()\n",
    "    detect_time = det_toc - det_tic\n",
    "    misc_tic = time.time()\n",
    "    if vis:\n",
    "        im = cv2.imread(imdb.image_path_at(i))\n",
    "        im2show = np.copy(im)\n",
    "    for j in range(1, imdb.num_classes):\n",
    "        inds = torch.nonzero(scores[:,j]>thresh).view(-1)\n",
    "        # if there is det\n",
    "        if inds.numel() > 0:\n",
    "            cls_scores = scores[:,j][inds]\n",
    "            _, order = torch.sort(cls_scores, 0, True)\n",
    "            if class_agnostic:\n",
    "                cls_boxes = pred_boxes[inds, :]\n",
    "            else:\n",
    "                cls_boxes = pred_boxes[inds][:, j * 4:(j + 1) * 4]\n",
    "            \n",
    "            cls_dets = torch.cat((cls_boxes, cls_scores.unsqueeze(1)), 1)\n",
    "            # cls_dets = torch.cat((cls_boxes, cls_scores), 1)\n",
    "            cls_dets = cls_dets[order]\n",
    "            keep = nms(cls_boxes[order, :], cls_scores[order], cfg.TEST.NMS)\n",
    "            cls_dets = cls_dets[keep.view(-1).long()]\n",
    "            if vis:\n",
    "                im2show = vis_detections(im2show, imdb.classes[j], cls_dets.cpu().numpy(), 0.3)\n",
    "            all_boxes[j][i] = cls_dets.cpu().numpy()\n",
    "        else:\n",
    "            all_boxes[j][i] = empty_array\n",
    "\n",
    "    # Limit to max_per_image detections *over all classes*\n",
    "    if max_per_image > 0:\n",
    "        image_scores = np.hstack([all_boxes[j][i][:, -1]\n",
    "                                    for j in range(1, imdb.num_classes)])\n",
    "        if len(image_scores) > max_per_image:\n",
    "            image_thresh = np.sort(image_scores)[-max_per_image]\n",
    "            for j in range(1, imdb.num_classes):\n",
    "                keep = np.where(all_boxes[j][i][:, -1] >= image_thresh)[0]\n",
    "                all_boxes[j][i] = all_boxes[j][i][keep, :]\n",
    "\n",
    "    misc_toc = time.time()\n",
    "    nms_time = misc_toc - misc_tic\n",
    "\n",
    "    sys.stdout.write('im_detect: {:d}/{:d} {:.3f}s {:.3f}s   \\r' \\\n",
    "          .format(i + 1, num_images, detect_time, nms_time))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if vis:\n",
    "        cv2.imwrite('result.png', im2show)\n",
    "        pdb.set_trace()\n",
    "        #cv2.imshow('test', im2show)\n",
    "        #cv2.waitKey(0)\n",
    "\n",
    "with open(det_file, 'wb') as f:\n",
    "    pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('Evaluating detections')\n",
    "imdb.evaluate_detections(all_boxes, output_dir)\n",
    "\n",
    "end = time.time()\n",
    "print(\"eval time: %0.4fs\" % (end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
